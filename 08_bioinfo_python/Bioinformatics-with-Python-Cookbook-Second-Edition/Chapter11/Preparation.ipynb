{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget ftp://ngs.sanger.ac.uk/production/ag1000g/phase1/AR3/variation/crosses/ar3/hdf5/ag1000g.crosses.phase1.ar3sites.3L.h5\n",
    "# !wget ftp://ngs.sanger.ac.uk/production/ag1000g/phase1/AR3/variation/crosses/ar3/hdf5/ag1000g.crosses.phase1.ar3sites.2L.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('samples.tsv', sep='\\t')\n",
    "print(len(samples))\n",
    "print(samples['cross'].unique())\n",
    "print(samples[samples['cross'] == 'cross-29-2'][['id', 'function']])\n",
    "print(len(samples[samples['cross'] == 'cross-29-2']))\n",
    "print(samples[samples['function'] == 'parent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chromosome arm 3L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_3L = h5py.File('ag1000g.crosses.phase1.ar3sites.3L.h5', 'r')\n",
    "samples_hdf5 = list(map(lambda sample: sample.decode('utf-8'), h5_3L['/3L/samples']))\n",
    "\n",
    "calldata_genotype = h5_3L['/3L/calldata/genotype']\n",
    "\n",
    "MQ0 = h5_3L['/3L/variants/MQ0']\n",
    "MQ = h5_3L['/3L/variants/MQ']\n",
    "QD = h5_3L['/3L/variants/QD']\n",
    "Coverage = h5_3L['/3L/variants/Coverage']\n",
    "CoverageMQ0 = h5_3L['/3L/variants/CoverageMQ0']\n",
    "HaplotypeScore = h5_3L['/3L/variants/HaplotypeScore']\n",
    "QUAL = h5_3L['/3L/variants/QUAL']\n",
    "FS = h5_3L['/3L/variants/FS']\n",
    "DP = h5_3L['/3L/variants/DP']\n",
    "HRun = h5_3L['/3L/variants/HRun']\n",
    "ReadPosRankSum = h5_3L['/3L/variants/ReadPosRankSum']\n",
    "my_features = {\n",
    "    'MQ': MQ,\n",
    "    'QD': QD,\n",
    "    'Coverage': Coverage,\n",
    "    'HaplotypeScore': HaplotypeScore,\n",
    "    'QUAL': QUAL,\n",
    "    'FS': FS,\n",
    "    'DP': DP,\n",
    "    'HRun': HRun,\n",
    "    'ReadPosRankSum': ReadPosRankSum\n",
    "}\n",
    "\n",
    "num_features = len(my_features)\n",
    "num_alleles = h5_3L['/3L/variants/num_alleles']\n",
    "is_snp = h5_3L['/3L/variants/is_snp']\n",
    "POS = h5_3L['/3L/variants/POS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute mendelian errors (biallelic)\n",
    "def compute_mendelian_errors(mother, father, offspring):\n",
    "    num_errors = 0\n",
    "    num_ofs_problems = 0\n",
    "    if len(mother.union(father)) == 1:\n",
    "        # Mother and father are homo and the same\n",
    "        for ofs in offspring:\n",
    "            if len(ofs) == 2:\n",
    "                # Offspring is het\n",
    "                num_errors += 1\n",
    "                num_ofs_problems += 1\n",
    "            elif len(ofs.intersection(mother)) == 0:\n",
    "                # Offspring is homo, but opposite from parents\n",
    "                num_errors += 2\n",
    "                num_ofs_problems += 1\n",
    "    elif len(mother) == 1 and len(father) == 1:\n",
    "        # Mother and father are homo and different\n",
    "        for ofs in offspring:\n",
    "            if len(ofs) == 1:\n",
    "                # Homo, should be het\n",
    "                num_errors += 1\n",
    "                num_ofs_problems += 1\n",
    "    elif len(mother) == 2 and len(father) == 2:\n",
    "        # Both are het, individual offspring can be anything\n",
    "        pass\n",
    "    else:\n",
    "        # One is het, the other is homo\n",
    "        homo = mother if len(mother) == 1 else father\n",
    "        for ofs in offspring:\n",
    "            if len(ofs) == 1 and ofs.intersection(homo):\n",
    "                # homo, but not including the allele from parent that is homo\n",
    "                num_errors += 1\n",
    "                num_ofs_problems += 1\n",
    "    return num_errors, num_ofs_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceptable_position_to_genotype():\n",
    "    for i, genotype in enumerate(calldata_genotype):\n",
    "        if is_snp[i] and num_alleles[i] == 2:\n",
    "            if len(np.where(genotype == -1)[0]) > 1:\n",
    "                # Missing data\n",
    "                continue\n",
    "            yield i\n",
    "\n",
    "def acumulate(fun):\n",
    "    acumulator = {}\n",
    "    for res in fun():\n",
    "        if res is not None:\n",
    "            acumulator[res[0]] = res[1]\n",
    "    return acumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_family_indexes(samples_hdf5, cross_pd):\n",
    "    offspring = []\n",
    "    for i, individual in cross_pd.T.iteritems():\n",
    "        index = samples_hdf5.index(individual.id)\n",
    "        if individual.function == 'parent':\n",
    "            if individual.sex == 'M':\n",
    "                father = index\n",
    "            else:\n",
    "                mother = index\n",
    "        else:\n",
    "            offspring.append(index)\n",
    "    return {'mother': mother, 'father': father, 'offspring': offspring}\n",
    "\n",
    "cross_pd = samples[samples['cross'] == 'cross-29-2']\n",
    "family_indexes = get_family_indexes(samples_hdf5, cross_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mother_index = family_indexes['mother']\n",
    "father_index = family_indexes['father']\n",
    "offspring_indexes = family_indexes['offspring']\n",
    "all_errors = {}\n",
    "\n",
    "\n",
    "def get_mendelian_errors():\n",
    "    for i in acceptable_position_to_genotype():\n",
    "        genotype = calldata_genotype[i]\n",
    "        mother = set(genotype[mother_index])\n",
    "        father = set(genotype[father_index])\n",
    "        offspring = [set(genotype[ofs_index]) for ofs_index in offspring_indexes]\n",
    "        my_mendelian_errors = compute_mendelian_errors(mother, father, offspring)\n",
    "        yield POS[i], my_mendelian_errors\n",
    "\n",
    "mendelian_errors = acumulate(get_mendelian_errors)\n",
    "\n",
    "pickle.dump(mendelian_errors, gzip.open('mendelian_errors.pickle.gz', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_positions = sorted(mendelian_errors.keys())\n",
    "ordered_features = sorted(my_features.keys())  #XXX on code?\n",
    "num_features = len(ordered_features)\n",
    "feature_fit = np.empty((len(ordered_positions), len(my_features) + 2), dtype=float)\n",
    "\n",
    "for column, feature in enumerate(ordered_features):  # 'Strange' order\n",
    "    print(feature)\n",
    "    current_hdf_row = 0\n",
    "    for row, genomic_position in enumerate(ordered_positions):\n",
    "        while POS[current_hdf_row] < genomic_position:\n",
    "            current_hdf_row +=1\n",
    "        feature_fit[row, column] = my_features[feature][current_hdf_row]\n",
    "\n",
    "for row, genomic_position in enumerate(ordered_positions):\n",
    "    feature_fit[row, num_features] = genomic_position\n",
    "    feature_fit[row, num_features + 1] = 1 if mendelian_errors[genomic_position][0] > 0 else 0\n",
    "\n",
    "np.save(gzip.open('feature_fit.npy.gz', 'wb'), feature_fit, allow_pickle=False, fix_imports=False)\n",
    "pickle.dump(ordered_features, open('ordered_features', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chromosome arm 2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_2L = h5py.File('ag1000g.crosses.phase1.ar3sites.2L.h5', 'r')\n",
    "samples_hdf5 = list(map(lambda sample: sample.decode('utf-8'), h5_2L['/2L/samples']))\n",
    "calldata_DP = h5_2L['/2L/calldata/DP']\n",
    "POS = h5_2L['/2L/variants/POS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_indexes(samples_hdf5, parents_pd):\n",
    "    parents = []\n",
    "    for i, individual in parents_pd.T.iteritems():\n",
    "        index = samples_hdf5.index(individual.id)\n",
    "        parents.append(index)\n",
    "    return parents\n",
    "\n",
    "parents_pd = samples[samples['function'] == 'parent']\n",
    "parent_indexes = get_parent_indexes(samples_hdf5, parents_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dps = []\n",
    "for i, pos in enumerate(POS):\n",
    "    if random.random() > 0.01:\n",
    "        continue\n",
    "    pos_dp = calldata_DP[i]\n",
    "    parent_pos_dp = [pos_dp[parent_index] for parent_index in parent_indexes]\n",
    "    all_dps.append(parent_pos_dp + [pos])\n",
    "all_dps = np.array(all_dps)\n",
    "np.save(gzip.open('DP_2L.npy.gz', 'wb'), all_dps, allow_pickle=False, fix_imports=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
